{"id":"matrix-synapse-deployment-0sn","title":"Documentation and examples for file upload integration","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:33.655745143Z","updated_at":"2025-12-22T23:46:33.655745143Z","comments":[{"id":13,"issue_id":"matrix-synapse-deployment-0sn","author":"node","text":"## Objective\n\nCreate comprehensive documentation for the file upload feature.\n\n## Documentation\n\n1. **User Guide**: How to use file upload feature\n2. **Admin Guide**: Configuration and deployment\n3. **API Reference**: Docling and Letta API usage\n4. **Troubleshooting**: Common issues and solutions\n\n## Examples\n\n- Sample Python client for testing\n- curl commands for API testing\n- Configuration templates\n\n## Location\n\n- BookStack: Letta Integration book\n- Project README\n\n## Acceptance Criteria\n\n- [ ] User-facing documentation complete\n- [ ] Admin deployment guide\n- [ ] Code examples working\n- [ ] Troubleshooting guide\n\n---\nHuly Issue: MXSYN-18","created_at":"2025-12-22T23:46:33Z"}]}
{"id":"matrix-synapse-deployment-1cd","title":"Implement retry logic for failed conversions","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:32.703293485Z","updated_at":"2025-12-22T23:46:32.703293485Z","comments":[{"id":7,"issue_id":"matrix-synapse-deployment-1cd","author":"node","text":"## Objective\n\nAdd robust error handling and retry logic for document processing.\n\n## Implementation\n\n1. Retry failed Docling requests (max 3 attempts)\n2. Exponential backoff between retries\n3. Queue failed jobs for later retry\n4. Alert on persistent failures\n\n## Error Scenarios\n\n- Docling service unavailable\n- Timeout on large documents\n- Corrupt/invalid file format\n- Rate limiting\n\n## Acceptance Criteria\n\n- [ ] Transient failures auto-retry\n- [ ] Persistent failures logged and alerted\n- [ ] User notified of final failure status\n- [ ] Failed jobs can be manually retried\n\n---\nHuly Issue: MXSYN-13","created_at":"2025-12-22T23:46:32Z"}]}
{"id":"matrix-synapse-deployment-1dr","title":"Testing: Streaming Unit and Integration Tests","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:31.545776647Z","updated_at":"2025-12-22T23:46:31.645795055Z","closed_at":"2025-12-22T23:46:31.645795055Z","close_reason":"Closed","comments":[{"id":2,"issue_id":"matrix-synapse-deployment-1dr","author":"node","text":"# Streaming Tests\n\n## Unit Tests\n\n### \n\n- [ ] Test  initialization\n- [ ] Test event parsing for each message type\n- [ ] Test error handling (timeout, connection error)\n- [ ] Test message normalization\n- [ ] Mock Letta SDK stream responses\n\n### Test Cases\n\n\n\n## Integration Tests\n\n### \n\n- [ ] Real streaming against test agent\n- [ ] Long-running operation with background mode\n- [ ] Connection recovery simulation\n- [ ] Multi-step tool chain streaming\n\n### Test Scenarios\n\n1. Simple prompt → Single assistant response\n2. Search prompt → tool_call → tool_return → assistant\n3. Complex prompt → Multiple tool calls → Multiple returns → assistant\n4. Error scenario → LLM error → Graceful failure\n5. Long operation → Background mode → Recovery\n\n## Manual Testing Checklist\n\n- [ ] Basic message in Matrix triggers streaming\n- [ ] Tool progress visible during execution\n- [ ] Final response correct\n- [ ] No duplicate messages\n- [ ] Error messages clear\n- [ ] Works with different agents\n- [ ] Fallback works when streaming disabled\n\n## Test Data\n\n- Simple agent without tools\n- Agent with conversation_search tool\n- Agent with multiple tools\n- Agent with long-running tools\n\n---\nHuly Issue: MXSYN-25","created_at":"2025-12-22T23:46:31Z"}]}
{"id":"matrix-synapse-deployment-2lx","title":"Implement Letta Streaming for Matrix Client","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:31.451589806Z","updated_at":"2025-12-22T23:46:31.494284314Z","closed_at":"2025-12-22T23:46:31.494284314Z","close_reason":"Closed"}
{"id":"matrix-synapse-deployment-48r","title":"[BLOCKER] Expose Docling API port in docker-compose","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:33.464412291Z","updated_at":"2025-12-22T23:46:33.545051244Z","closed_at":"2025-12-22T23:46:33.545051244Z","close_reason":"Closed","comments":[{"id":12,"issue_id":"matrix-synapse-deployment-48r","author":"node","text":"## Problem - RESOLVED ✅\n\nThe Docling container is now running with exposed ports.\n\n## Current Status\n\n- **API**: http://192.168.50.90:3057/docs (Swagger UI)\n- **Flower Monitoring**: http://192.168.50.90:3058\n- **Services**: 5 containers (API, Redis, 2 workers, Flower)\n- **Stack**: \n\n## Next Steps\n\n- [ ] Test API endpoint with sample PDF\n- [ ] Document authentication method (if any)\n- [ ] Verify Markdown output format\n\n## Related\n\n- MXSYN-2: Clarify Docling API specifications\n\n---\nHuly Issue: MXSYN-1","created_at":"2025-12-22T23:46:33Z"}]}
{"id":"matrix-synapse-deployment-4hj","title":"Add environment configuration for file upload integration","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:33.599676036Z","updated_at":"2025-12-22T23:46:33.599676036Z"}
{"id":"matrix-synapse-deployment-4y6","title":"Performance optimization for document processing","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:33.92327493Z","updated_at":"2025-12-22T23:46:33.92327493Z","comments":[{"id":16,"issue_id":"matrix-synapse-deployment-4y6","author":"node","text":"## Objective\n\nOptimize processing pipeline for speed and resource efficiency.\n\n## Optimizations\n\n1. Parallel processing for multiple uploads\n2. Caching for repeated document uploads\n3. Optimize Docling worker configuration\n4. Stream large files instead of loading to memory\n\n## Targets\n\n- Processing time \u003c 30s for 10-page PDF\n- Support 5+ concurrent conversions\n- Memory usage \u003c 500MB per conversion\n\n## Acceptance Criteria\n\n- [ ] Benchmark current performance\n- [ ] Implement optimizations\n- [ ] Verify targets met\n- [ ] Document configuration tuning\n\n---\nHuly Issue: MXSYN-15","created_at":"2025-12-22T23:46:33Z"}]}
{"id":"matrix-synapse-deployment-5e5","title":"Implement Matrix notification for processing status","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:32.072091016Z","updated_at":"2025-12-22T23:46:32.152753453Z","closed_at":"2025-12-22T23:46:32.152753453Z","close_reason":"Closed","comments":[{"id":4,"issue_id":"matrix-synapse-deployment-5e5","author":"node","text":"## Objective\n\nNotify users in Matrix when file processing completes or fails.\n\n## Implementation\n\n1. Send success message: \n2. Send error message: \n3. Optional: Send progress updates for large files\n\n## Message Format\n\n\n\n## Error Format\n\n\n\n## Acceptance Criteria\n\n- [ ] Success notification sent to room\n- [ ] Error notification with helpful message\n- [ ] Messages formatted cleanly\n\n---\nHuly Issue: MXSYN-9","created_at":"2025-12-22T23:46:32Z"}]}
{"id":"matrix-synapse-deployment-5mn","title":"Add user configuration options for file processing","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:33.744578503Z","updated_at":"2025-12-22T23:46:33.744578503Z","comments":[{"id":14,"issue_id":"matrix-synapse-deployment-5mn","author":"node","text":"## Objective\n\nAllow users to configure file processing preferences.\n\n## Configuration Options\n\n1. **Auto-process**: Enable/disable automatic processing (opt-in)\n2. **Notifications**: Always / Errors only / Never\n3. **File types**: Which types to process\n4. **Privacy**: Mark files as \"do not index\"\n\n## Implementation\n\n- Room-level settings via Matrix state events\n- User preferences via bot commands\n- Default configuration in environment\n\n## Commands\n\n\n\n## Acceptance Criteria\n\n- [ ] Room-level configuration works\n- [ ] User preferences respected\n- [ ] Defaults are sensible (opt-in recommended)\n\n---\nHuly Issue: MXSYN-17","created_at":"2025-12-22T23:46:33Z"}]}
{"id":"matrix-synapse-deployment-5rx","title":"Phase 4: Investigate Token Streaming (Deferred)","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:31.885102366Z","updated_at":"2025-12-22T23:46:31.885102366Z","comments":[{"id":3,"issue_id":"matrix-synapse-deployment-5rx","author":"node","text":"# Token Streaming Investigation\n\n## Status: DEFERRED\n\nToken streaming () is currently not returning content chunks from the Letta server.\n\n## Current Behavior\n\nWhen :\n\n- Only  and  events received\n- No  or  chunks\n- Same behavior on direct API (port 8283) and proxy (port 8289)\n\n## Expected Behavior (per Letta docs)\n\nShould receive multiple chunks with same message ID:\n\n\n\n## Investigation Tasks\n\n- [ ] Test with different agents/models (GPT-4o, Gemini)\n- [ ] Check Letta server version\n- [ ] Review server logs for errors\n- [ ] Test on Letta Cloud vs self-hosted\n- [ ] Check if Claude Sonnet 4 supports token streaming via Letta\n\n## Potential Causes\n\n1. **Model limitation**: Claude Sonnet 4 may not support token streaming through Letta\n2. **Server configuration**: Token streaming may need to be enabled\n3. **Agent configuration**: May need specific agent settings\n4. **SDK version**: May need SDK update\n\n## Impact if Not Fixed\n\n- Step streaming provides adequate UX for most use cases\n- Token streaming mainly improves perceived latency\n- Not blocking for MVP\n\n## References\n\n- Letta docs: https://docs.letta.com/guides/agents/streaming/\n- Test script: \n\n---\nHuly Issue: MXSYN-24","created_at":"2025-12-22T23:46:31Z"}]}
{"id":"matrix-synapse-deployment-69x","title":"Add processing progress updates in Matrix","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:31.324466956Z","updated_at":"2025-12-22T23:46:31.401597834Z","closed_at":"2025-12-22T23:46:31.401597834Z","close_reason":"Closed","comments":[{"id":1,"issue_id":"matrix-synapse-deployment-69x","author":"node","text":"## Objective\n\nProvide real-time progress updates for large document processing.\n\n## Implementation\n\n1. Send \"Processing started\" message immediately\n2. Update with progress for multi-page documents\n3. Send completion message with stats\n\n## Message Flow\n\n\n\n## Acceptance Criteria\n\n- [ ] Immediate acknowledgment of upload\n- [ ] Progress updates for large files (\u003e10 pages)\n- [ ] Final status with processing stats\n\n---\nHuly Issue: MXSYN-14","created_at":"2025-12-22T23:46:31Z"}]}
{"id":"matrix-synapse-deployment-7ir","title":"Implement Docling API client for document conversion","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:33.232181373Z","updated_at":"2025-12-22T23:46:33.273903034Z","closed_at":"2025-12-22T23:46:33.273903034Z","close_reason":"Closed"}
{"id":"matrix-synapse-deployment-8jj","title":"Add monitoring and alerting for file processing","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:33.833888619Z","updated_at":"2025-12-22T23:46:33.833888619Z","comments":[{"id":15,"issue_id":"matrix-synapse-deployment-8jj","author":"node","text":"## Objective\n\nImplement observability for the file processing pipeline.\n\n## Metrics to Track\n\n- Files processed (daily/weekly)\n- Processing time distribution\n- Error rate by file type\n- Queue depth (pending files)\n- Docling worker health\n\n## Monitoring Stack\n\n- Flower UI for Celery monitoring (http://192.168.50.90:3058)\n- Custom metrics endpoint\n- Alert on high error rate or queue backup\n\n## Acceptance Criteria\n\n- [ ] Dashboard showing key metrics\n- [ ] Alerts for failures \u003e 5%\n- [ ] Alerts for queue \u003e 10 items\n- [ ] Historical data retention\n\n---\nHuly Issue: MXSYN-16","created_at":"2025-12-22T23:46:33Z"}]}
{"id":"matrix-synapse-deployment-9zx","title":"Phase 2: Integrate Streaming into Matrix Client","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:31.69652089Z","updated_at":"2025-12-22T23:46:31.738714056Z","closed_at":"2025-12-22T23:46:31.738714056Z","close_reason":"Closed"}
{"id":"matrix-synapse-deployment-hjn","title":"Implement Letta folder management for Matrix rooms","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:32.298631894Z","updated_at":"2025-12-22T23:46:32.344442181Z","closed_at":"2025-12-22T23:46:32.344442181Z","close_reason":"Closed"}
{"id":"matrix-synapse-deployment-llm","title":"Add support for DOCX and PPTX formats","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:32.921839935Z","updated_at":"2025-12-22T23:46:33.00013226Z","closed_at":"2025-12-22T23:46:33.00013226Z","close_reason":"Closed","comments":[{"id":9,"issue_id":"matrix-synapse-deployment-llm","author":"node","text":"## Objective\n\nExtend document processing to support Microsoft Office formats.\n\n## Supported Formats\n\n- DOCX (Word documents)\n- PPTX (PowerPoint presentations)\n- TXT (plain text)\n- MD (Markdown passthrough)\n\n## Implementation\n\n1. Detect file type from mimetype/extension\n2. Send to Docling for conversion\n3. Handle multi-slide PPTX appropriately\n\n## Acceptance Criteria\n\n- [ ] DOCX converted to Markdown with formatting preserved\n- [ ] PPTX slides converted to structured Markdown\n- [ ] Plain text files handled correctly\n\n---\nHuly Issue: MXSYN-12","created_at":"2025-12-22T23:46:32Z"}]}
{"id":"matrix-synapse-deployment-lxg","title":"Implement Matrix file download from media repository","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:32.397575541Z","updated_at":"2025-12-22T23:46:32.476741475Z","closed_at":"2025-12-22T23:46:32.476741475Z","close_reason":"Closed","comments":[{"id":5,"issue_id":"matrix-synapse-deployment-lxg","author":"node","text":"## Objective\n\nDownload files from Matrix media repository for processing.\n\n## Implementation\n\n1. Convert  URL to HTTP download URL\n2. Download file with proper authentication\n3. Store temporarily for Docling processing\n4. Clean up after processing complete\n\n## API Reference\n\n\n\n## Acceptance Criteria\n\n- [ ] Successfully download files from mxc:// URLs\n- [ ] Handle authentication correctly\n- [ ] Temporary storage with cleanup\n- [ ] Error handling for failed downloads\n\n---\nHuly Issue: MXSYN-5","created_at":"2025-12-22T23:46:32Z"}]}
{"id":"matrix-synapse-deployment-m4f","title":"Clarify Docling API specifications","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:33.326941202Z","updated_at":"2025-12-22T23:46:33.410947001Z","closed_at":"2025-12-22T23:46:33.410947001Z","close_reason":"Closed","comments":[{"id":11,"issue_id":"matrix-synapse-deployment-m4f","author":"node","text":"## Objective\n\nDocument the exact Docling REST API interface for integration.\n\n## Known Information ✅\n\n- **API URL**: http://192.168.50.90:3057\n- **Swagger Docs**: http://192.168.50.90:3057/docs\n- **Flower Monitoring**: http://192.168.50.90:3058\n- **Architecture**: Celery-based async processing (Redis + 2 workers)\n\n## Questions to Answer\n\n1. **Endpoint Path**: What is the conversion endpoint? (? ?)\n2. **Authentication**: API key? Bearer token? None?\n3. **Request Format**: Multipart form-data or base64 JSON?\n4. **Response Format**: Confirm Markdown output structure\n5. **Async Processing**: How to poll for job completion?\n6. **File Size Limits**: Maximum supported file size?\n\n## Deliverable\n\n- [ ] Test API with sample PDF via Swagger UI\n- [ ] Document request/response format\n- [ ] Create code example for integration\n\n---\nHuly Issue: MXSYN-2","created_at":"2025-12-22T23:46:33Z"}]}
{"id":"matrix-synapse-deployment-n8v","title":"Implement Letta file upload with metadata","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:32.205151435Z","updated_at":"2025-12-22T23:46:32.245709304Z","closed_at":"2025-12-22T23:46:32.245709304Z","close_reason":"Closed"}
{"id":"matrix-synapse-deployment-nqw","title":"Phase 3: Long-Running Operation Support","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:31.981615245Z","updated_at":"2025-12-22T23:46:31.981615245Z"}
{"id":"matrix-synapse-deployment-q46","title":"Add OCR support for scanned PDFs and images","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:33.076702835Z","updated_at":"2025-12-22T23:46:33.160322961Z","closed_at":"2025-12-22T23:46:33.160322961Z","close_reason":"Closed","comments":[{"id":10,"issue_id":"matrix-synapse-deployment-q46","author":"node","text":"## Objective\n\nEnable OCR extraction for scanned documents and images.\n\n## Implementation\n\n1. Detect if PDF is scanned (no selectable text)\n2. Enable OCR in Docling request for images (PNG, JPG)\n3. Handle mixed documents (some pages scanned, some not)\n\n## Supported Formats\n\n- Scanned PDFs\n- PNG images\n- JPG/JPEG images\n\n## Acceptance Criteria\n\n- [ ] OCR extracts text from scanned PDFs\n- [ ] Images converted to searchable Markdown\n- [ ] OCR accuracy \u003e 95% for clear scans\n- [ ] Processing time \u003c 30s for typical 10-page document\n\n---\nHuly Issue: MXSYN-11","created_at":"2025-12-22T23:46:33Z"}]}
{"id":"matrix-synapse-deployment-q53","title":"Phase 1: Implement Step Streaming Adapter","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:31.7904337Z","updated_at":"2025-12-22T23:46:31.832874066Z","closed_at":"2025-12-22T23:46:31.832874066Z","close_reason":"Closed"}
{"id":"matrix-synapse-deployment-uoo","title":"Implement Matrix file upload event detection","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:32.528620602Z","updated_at":"2025-12-22T23:46:32.613681846Z","closed_at":"2025-12-22T23:46:32.613681846Z","close_reason":"Closed","comments":[{"id":6,"issue_id":"matrix-synapse-deployment-uoo","author":"node","text":"## Objective\n\nDetect file upload events in Matrix rooms and trigger processing pipeline.\n\n## Implementation\n\n1. Monitor  events with \n2. Extract file metadata:\n   -  (mxc:// URL)\n   - \n   -  (mimetype)\n   - \n   - \n   - \n   - \n3. Filter by supported file types: \n4. Filter by max size: 50MB\n\n## Location\n\n\n\n## Acceptance Criteria\n\n- [ ] File uploads detected in real-time\n- [ ] Metadata extracted correctly\n- [ ] Unsupported files ignored with optional notification\n- [ ] Large files rejected with user notification\n\n---\nHuly Issue: MXSYN-4","created_at":"2025-12-22T23:46:32Z"}]}
{"id":"matrix-synapse-deployment-xf5","title":"Document Letta Filesystem API for folder/file operations","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-22T23:46:32.793768143Z","updated_at":"2025-12-22T23:46:32.793768143Z","comments":[{"id":8,"issue_id":"matrix-synapse-deployment-xf5","author":"node","text":"## Objective\n\nClarify and document Letta Filesystem API endpoints needed for integration.\n\n## API Endpoints to Document\n\n1. **List folders**: \n2. **Create folder**: \n3. **Upload file to folder**: \n4. **Attach folder to agent**: \n5. **Job status**: \n\n## Questions\n\n- How does file chunking work?\n- What embedding model is used by default?\n- How to pass metadata (source, room_id, sender)?\n- Job polling interval for upload completion?\n\n## Deliverable\n\nCode examples or SDK usage documentation\n\n## Reference\n\n- Letta API: https://letta.oculair.ca\n- PRD folder strategy: One folder per Matrix room ()\n\n---\nHuly Issue: MXSYN-3","created_at":"2025-12-22T23:46:32Z"}]}
