services:
  # Tuwunel Matrix Homeserver (replacing Synapse)
  # Using custom-built image compatible with Docker 20.10.24
  tuwunel:
    image: ghcr.io/oculairmedia/tuwunel-docker2010:latest
    restart: unless-stopped
    command: ["-c", "/var/lib/tuwunel/tuwunel.toml", "-O", "address=\"0.0.0.0\"", "-O", "port=6167"]
    environment:
      - TUWUNEL_SERVER_NAME=${MATRIX_SERVER_NAME:-matrix.oculair.ca}
      - TUWUNEL_DATABASE_PATH=/var/lib/tuwunel
      - TUWUNEL_ALLOW_REGISTRATION=true
      - TUWUNEL_REGISTRATION_TOKEN=matrix_mcp_secret_token_2024
      - TUWUNEL_MAX_REQUEST_SIZE=20000000
      - TUWUNEL_ALLOW_FEDERATION=true
      - TUWUNEL_ALLOW_CHECK_FOR_UPDATES=true
      - TUWUNEL_TRUSTED_SERVERS=["matrix.org"]
      - TUWUNEL_LOG=info
    volumes:
      - ${TUWUNEL_DATA_PATH:-./tuwunel-data}:/var/lib/tuwunel
    networks:
      - matrix-internal
    ports:
      - "6167:6167"  # Matrix federation/client port
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:6167/_matrix/client/versions"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Element Web Client
  element:
    image: vectorim/element-web:latest
    restart: unless-stopped
    volumes:
      - ${ELEMENT_CONFIG_PATH}:/app/config.json:ro
    networks:
      - matrix-internal

  # Nginx reverse proxy
  nginx:
    image: nginx:alpine
    restart: unless-stopped
    ports:
      - ${NGINX_HTTP_PORT:-8008}:80
      - "8448:8448"  # Matrix federation port
    volumes:
      - ./nginx_tuwunel_proxy.conf:/etc/nginx/conf.d/default.conf:ro
    networks:
      - matrix-internal
    depends_on:
      - tuwunel
      - element
    labels:
      - "homepage.group=Communication"
      - "homepage.name=Matrix Homeserver (Tuwunel)"
      - "homepage.icon=si-matrix"
      - "homepage.href=http://matrix.oculair.ca"
      - "homepage.description=Tuwunel Matrix homeserver with Element web client"

  # Matrix Client with Agent Management
  matrix-client:
    image: ghcr.io/oculairmedia/letta-matrix-client:latest
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - MATRIX_HOMESERVER_URL=http://tuwunel:6167
    volumes:
      - ./matrix_store:/app/matrix_store
      - ./matrix_client_data:/app/data
      - ./custom_matrix_client.py:/app/custom_matrix_client.py:ro
      - ./agent_user_manager.py:/app/agent_user_manager.py:ro
      - ./matrix_auth.py:/app/matrix_auth.py:ro
    networks:
      - matrix-internal
    depends_on:
      tuwunel:
        condition: service_healthy
      matrix-api:
        condition: service_started
      whisper:
        condition: service_healthy
    healthcheck:
      test:
        - CMD
        - python
        - -c
        - import sys; sys.exit(0)
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Matrix API Service
  matrix-api:
    image: ghcr.io/oculairmedia/letta-matrix-api:latest
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - MATRIX_HOMESERVER_URL=http://tuwunel:6167
    volumes:
      - ./matrix_client_data:/app/data
    ports:
      - 8004:8000
    networks:
      - matrix-internal
    depends_on:
      - tuwunel
    labels:
      - "homepage.group=Communication"
      - "homepage.name=Matrix API"
      - "homepage.icon=si-api"
      - "homepage.href=http://192.168.50.90:8004"
      - "homepage.description=Matrix API server for automation"


  # Speaches - Local Speech-to-Text (faster-whisper)
  whisper:
    image: ghcr.io/speaches-ai/speaches:latest-cuda-12.6.3
    restart: unless-stopped
    ports:
      - "8890:8000"   # OpenAI-compatible STT API (used by LiveKit agent worker)
    environment:
      - WHISPER__INFERENCE_DEVICE=cuda
      - WHISPER__COMPUTE_TYPE=float16
      - PRELOAD_MODELS=["Systran/faster-whisper-medium"]
      - STT_MODEL_TTL=-1
    volumes:
      - whisper-models:/home/ubuntu/.cache/huggingface/hub
    networks:
      - matrix-internal
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s  # First run downloads model

networks:
  matrix-internal:
    driver: bridge

volumes:
  whisper-models:
